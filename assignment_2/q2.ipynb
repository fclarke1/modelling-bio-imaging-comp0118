{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    " - estimating the noise. Best to use measurements against g-t. Using a histogram loses the order and discretizes the data so not the best estiumate of the error\n",
    "  - 3.1 objective is the sum of squares error\n",
    "\n",
    "v2 script\n",
    " - betaGT is 2 element array, with beta[0] having slope, and beta[1] the interecept\n",
    " - J is the interecept array of only 1s in a single column, X is the design matrix of [J; x]\n",
    "\n",
    "Uncertainty\n",
    " - In virtual environment we can do better than bootstrap. We can just generate new data N times. This gives the best estimate of uncertainty we can get for our parameters (slope, intercept) -> we expect the distribution of each parameter to be Gaussian\n",
    "    - This is because if y is gaussian distirbuted -> multiple, addition, etc. is also gaussian.\n",
    "    - different parameters have different var because they have different operations on them so can work out what their expected var should be\n",
    "    - NOTE: the var estimate of data is NOT gaussian. It is Chi-squared distributed\n",
    "\n",
    "Variable Space\n",
    " - 1 axis for each variable\n",
    " \n",
    "Subject Space\n",
    " - 1 axis for each observation. So N observations we are in a R^N space\n",
    " - Each point represents all observations for that variable (so an arrow for each variable)\n",
    " - solution space is the hyper-plane created by using the bias arrow, and the arrows for predictor arrows. The outcome arrow stays in this hyper-plane (solution space) if there is no noise -> indicates the model describes the data perfectly#\n",
    " - the least Squares solution will find the solution that gives the smallest distance between the solution space and the outcome arrow\n",
    " - error space is orthogonal to the solution space. We can tell apart the noise from the model for any error in the error space. dim of error space is n-p where n is number of measurements and we have p parameters. Any error in error space will be seen as error, and not incorporated in the model\n",
    "  - estimation space is error within the solution space which we can't tell apart from the model. This is because the model will interpret the error as true signal\n",
    "  - We want as many measurements as possible to get the error space to be much higher dim than the estimation space which will reduce the variance of our model\n",
    "\n",
    "How do we know slope/beta is zero?\n",
    " - Use the null hypothesis of beta being zero, and find the p-value of it not being zero\n",
    " - how do we do this if we don't know the underlying noise? We can use permutation test which doesn't make strong assumptions on the noise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MV00-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9175f14313f4b35742ea6c52a4ce22cd1fcfedf80e7f8b431e13de372660966e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
